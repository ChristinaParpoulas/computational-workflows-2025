{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Workflows for biomedical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the course Computational Workflows for Biomedical Data. Over the next two weeks, you will learn how to leverage nf-core pipelines to analyze biomedical data and gain hands-on experience in creating your own pipelines, with a strong emphasis on Nextflow and nf-core.\n",
    "\n",
    "Course Structure:\n",
    "\n",
    "- Week 1: You will use a variety of nf-core pipelines to analyze a publicly available biomedical study.\n",
    "- Week 2: We will shift focus to learning the basics of Nextflow, enabling you to design and implement your own computational workflows.<br>\n",
    "- Final Project: The last couple of days, you will apply your knowledge to create a custom pipeline for analyzing biomedical data using Nextflow and the nf-core template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "If you have not installed all required software, please do so now asap!\n",
    "\n",
    "\n",
    "If you already installed all software, please go on and start answering the questions in this notebook. If you have any questions, don't hesitate to approach us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is nf-core?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "A global community collaborating to build open-source Nextflow components and pipelines.\n",
    "All nf-core code is community owned.\n",
    "Everyone is welcome to use, contribute to, and help maintain nf-core.\n",
    "\n",
    "Quelle: https://nf-co.re/about, https://nf-co.re/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many pipelines are there currently in nf-core?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 139 pipelines available as part of nf-core.\n",
    "\n",
    "Quelle: https://nf-co.re/pipelines/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Are there any non-bioinformatic pipelines in nf-core?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most pipelines seem to be bioinformatic pipelines, however for example rangeland seem to be not bioinformatic in a classical way. It is a geographical best-practice analysis pipeline for remotely sensed imagery. The pipeline processes satellite imagery alongside auxiliary data in multiple steps to arrive at a set of trend files related to land-cover changes.\n",
    "\n",
    "Quelle: https://nf-co.re/rangeland/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's go back a couple of steps. What is a pipeline and what do we use it for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline\n",
    "\n",
    "It is a set of ordered computational steps that take data as input, perform some specific analyses (e.g. alignment, quality control, ...), and produce results as output. Each step within a pipeline is usually reusable, and its ensures that they are connected in the correct order with the right dependencies and resources.\n",
    "\n",
    "What do we use it for?\n",
    "\n",
    "Instead of manually running each tool and handling intermediate files, the pipeline runs everything in the right order. With nf-core pipelines the version of each individual tool used/step done is version-controlled, tested, and containerized, so the same analysis can be reproduced anywhere.\n",
    "They can be run on any laptop, cluster, or cloud without rewriting code and follow strict guidelines for best practices, making them reliable and easier to share.\n",
    "\n",
    "Quelle: input lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Why do you think nf-core adheres to strict guidelines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nf-core follows strict guidelines because it wants all pipelines to follow the FAIR principles. It wants pipelines to be reproducible, consistent, maintainable (follow the same coding style), trustworthy (quality standards) and portable & scalable (as mentioned above).\n",
    "\n",
    "QUelle: https://nf-co.re/docs/guidelines/pipelines/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "6. What are the main features of nf-core pipelines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nf-core provides fully featured pipelines:\n",
    "\n",
    "- Documentation covering installation, usage, and description of output files.\n",
    "- Release of pipelines with tag to stable version.\n",
    "- Open Source: licenced unter the MIT licence.\n",
    "- CI Testing: Uses continuous-integration testing for changed made to pipelines.\n",
    "- Pipelines are ultra-portable (can run everywhere: laptop, cluster, ...)\n",
    "- Packaged Software: Also dependencies are downloaded and handeled automatically.\n",
    "\n",
    "Quelle: https://nf-co.re/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Let's start using the pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the nf-core pipeline used to measure differential abundance of genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nf-core/differentialabundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chrissi/BioPrak/computational-workflows-2025/notebooks/day_01\n"
     ]
    }
   ],
   "source": [
    "# run the pipeline in a cell \n",
    "# to run bash in jupyter notebooks, simply use ! before the command\n",
    "# e.g.\n",
    "\n",
    "!pwd\n",
    "\n",
    "\n",
    "# For the tasks in the first week, please use the command line to run your commands \n",
    "# and simply paste the commands you used in the respective cells!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pipeline in the test profile using docker containers\n",
    "# make sure to specify the version you want to use (use the latest one)\n",
    "\n",
    "\n",
    "!nextflow run nf-core/differentialabundance -r 1.5.0 -profile test,docker --outdir './results'\n",
    "# --outdir specifies the output folder\n",
    "\n",
    "# Other options one might want to use:\n",
    "# --max_memory '16.GB'  # specify max memory\n",
    "# --max_cpus '4'       # specify max cpus\n",
    "# --max_time '2.h'     # specify max time\n",
    "# --email '\n",
    "# --reads 'data/*_{1,2}.fastq.gz'  # specify input files\n",
    "# --design 'data/design.csv'       # specify design file\n",
    "# --contrast 'condition A - condition B'  # specify contrast\n",
    "# --save_reference  # save reference files (e.g. genome index files)\n",
    "# --save_alignments  # save alignment files (e.g. bam files)\n",
    "#\n",
    "# sigularity can be used instead of docker if preferred\n",
    "# \n",
    "# For more options, check the nf-core/differentialabundance documentation: https://nf-co.re/differentialabundance/usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the run. What did change?\n",
    "\n",
    "!nextflow run nf-core/differentialabundance -r 1.5.0 -profile test,docker --outdir './results'\n",
    "\n",
    "# Runtime decreased from 9min 47s to 3min 28s minutes.\n",
    "# Because docker pulls software that's packaged into a containers, it does not need to be installed again for a second run\n",
    "# However, the pipeline still needs to download the test data again and re-run all steps (all steps are executed again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now set -resume to the command. What did change?\n",
    "\n",
    "!nextflow run nf-core/differentialabundance -r 1.5.0 -profile test,docker --outdir './results' -resume\n",
    "\n",
    "# -resume will use the files that were already downloaded and calculated in the previous runs\n",
    "# So it will not download and calculate everything from scratch again\n",
    "# It will only re-run steps that were not completed in the previous run (e.g. for minor changes in the command)\n",
    "# Runtime is 1min 52s, which is much faster than the previous runtimes\n",
    "# So -resume is very useful when re-running the same analysis with only small changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the current directory. Next to the outdir you specified, what else has changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- During the runs, folders are created within a work folder \n",
    "- also at the main directory netxflow.log-files were created for each run that was performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the work directory and run the pipeline again using -resume. What did change?\n",
    "# Work folder was renamed to work_deleted\n",
    "\n",
    "!nextflow run nf-core/differentialabundance -r 1.5.0 -profile test,docker --outdir './results' -resume\n",
    "\n",
    "# It is again starting to download and calculate everything from scratch.\n",
    "# The work file seems to include all the calculations needed to build on when using resume\n",
    "# So when the work folder is deleted, resume cannot use any of the previous calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What changed?\n",
    "\n",
    "- It is again starting to download and calculate everything from scratch.\n",
    "- The work file seems to include all the calculations needed to build on when using resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is differential abundance analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the most important plots from the report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
